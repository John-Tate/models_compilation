{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "From Scikit-Learn:\n",
    "\n",
    "\"Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "The advantages of support vector machines are:\n",
    "* Effective in high dimensional spaces.\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "* If the number of features is much greater than the number of samples, the method is likely to give poor performances.\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd # For good measure\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## Import our dataset to work with\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data')\n",
    "\n",
    "data.columns = ['recency', 'frequency', 'volume_donated', 'months_since_first_donate', 'donated_march07']\n",
    "\n",
    "## define our features as X and our target as y\n",
    "X = data.drop('donated_march07', axis = 1)\n",
    "y = data['donated_march07']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "## splitting our data into 70% training and 30% testing with test size = .3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Instantiate our SVC model\n",
    "svc = SVC(probability = True)  ## Probability=True allows us to get\n",
    "                               ##\n",
    "\n",
    "# Fit our model on predefined training data\n",
    "svc_fit = svc.fit(X_train,y_train)\n",
    "\n",
    "# creating a set of predictions for our y_tests in order to check model accuracy\n",
    "y_preds = svc_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy Score:  0.733333333333\n",
      "SVC Precision:  0.545454545455\n",
      "SVC Recall:  0.0983606557377\n",
      "\n",
      "confusion matrix\n",
      "[[159   5]\n",
      " [ 55   6]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.97      0.84       164\n",
      "          1       0.55      0.10      0.17        61\n",
      "\n",
      "avg / total       0.69      0.73      0.66       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing metrics in order to make classification report and get accuracy score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Here i am getting the accuracy score by comparing our predicted outputs for the y_test\n",
    "# values (y_pred), to the actual y_test values\n",
    "lgr_accuracy = metrics.accuracy_score(y_preds, y_test)\n",
    "\n",
    "#creating a string of the type of model\n",
    "modelname = 'SVC'\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_preds)\n",
    "precision = metrics.precision_score(y_test,y_preds)\n",
    "recall = metrics.recall_score(y_test,y_preds)\n",
    "classification_report = metrics.classification_report(y_test, y_preds)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_preds)\n",
    "\n",
    "print modelname,\"Accuracy Score: \", accuracy\n",
    "# this is the precision score for the target output of 1\n",
    "print modelname,\"Precision: \", precision\n",
    "# this is the recall score for the target output of 1\n",
    "print modelname,\"Recall: \", recall\n",
    "print\n",
    "print 'confusion matrix\\n', confusion_matrix\n",
    "print\n",
    "print (metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2c7ee1babb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# is a 1. For example, if the predic_proba value is .34, there is a 34% chance that datapoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# is a 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#False Positive Rate, True Poisitive Rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TerryONeill/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \"\"\"\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TerryONeill/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    578\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "# We have already imported metrics which is what we need to build the ROC Curve\n",
    "\n",
    "# ROC - Reciever Operating Characteristic, used to measure basically the False Positive\n",
    "# rate (x-axis) against the true positive rate (y-axis)\n",
    "\n",
    "## Insert your instantiated and fit model below\n",
    "model = svc_fit\n",
    "\n",
    "\n",
    "#Here we are creating our predicted probabilities. This goes beyond whether something is\n",
    "# predicted as a 1 or a zero, but is their actual probability (from 0 to 1) that the output\n",
    "# is a 1. For example, if the predic_proba value is .34, there is a 34% chance that datapoint\n",
    "# is a 1\n",
    "y_probs = model.predict_proba(X_test)\n",
    "\n",
    "#False Positive Rate, True Poisitive Rate\n",
    "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_probs[:,1])\n",
    "roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "#### Plot the ROC Curve\n",
    "\n",
    "# choosing a background style for our graph\n",
    "plt.style.use('ggplot')\n",
    "# increasing the size of the figure\n",
    "plt.figure(figsize = (13, 11))\n",
    "#giving the graph a title\n",
    "plt.title('Receiver Operating Characteristic', fontsize = 24)\n",
    "# plotting the fpr and tpr that were defined above on our graph\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "# creating a legend in the lower right section of the graph with the plot label\n",
    "plt.legend(loc='lower right', fontsize = 24)\n",
    "#drawing a dashed straight line from points (0, 0) to (1, 1)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "# setting the scale for each axis\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "# drawing the axis lines and x and y = 0\n",
    "plt.axhline(0, color='black')\n",
    "plt.axvline(0, color='black')\n",
    "#labeling the x and y axes\n",
    "plt.ylabel('True Positive Rate', fontsize = 24)\n",
    "plt.xlabel('False Positive Rate', fontsize = 24)\n",
    "# showing our plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
